{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P59NYU98GCb9"
      },
      "outputs": [],
      "source": [
        "#################################### Correct your environment if needed! ##########################################\n",
        "\n",
        "# !pip3 -qq install torch==0.4.1\n",
        "# !pip3 -qq install bokeh==0.13.0\n",
        "# !pip3 -qq install gensim==3.6.0\n",
        "# !pip3 -qq install nltk\n",
        "# !pip3 -qq install scikit-learn==0.20.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sVtGHmA9aBM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6CNKM3b4hT1"
      },
      "source": [
        "# Рекуррентные нейронные сети (RNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_XkoGNQUeGm"
      },
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFEtWrS_4rUs"
      },
      "source": [
        "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
        "\n",
        "Мы порешаем сейчас POS Tagging для английского.\n",
        "\n",
        "Будем работать с таким набором тегов:\n",
        "- ADJ - adjective (new, good, high, ...)\n",
        "- ADP - adposition (on, of, at, ...)\n",
        "- ADV - adverb (really, already, still, ...)\n",
        "- CONJ - conjunction (and, or, but, ...)\n",
        "- DET - determiner, article (the, a, some, ...)\n",
        "- NOUN - noun (year, home, costs, ...)\n",
        "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
        "- PRT - particle (at, on, out, ...)\n",
        "- PRON - pronoun (he, their, her, ...)\n",
        "- VERB - verb (is, say, told, ...)\n",
        "- . - punctuation marks (. , ;)\n",
        "- X - other (ersatz, esprit, dunno, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPIkKdFlHB-X"
      },
      "source": [
        "Скачаем данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiA2dGmgF1rW"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d93g_swyJA_V"
      },
      "source": [
        "Пример размеченного предложения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QstS4NO0L97c",
        "outputId": "3fb123c6-640e-4538-e725-b7b0ad2790fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The            \tDET\n",
            "Fulton         \tNOUN\n",
            "County         \tNOUN\n",
            "Grand          \tADJ\n",
            "Jury           \tNOUN\n",
            "said           \tVERB\n",
            "Friday         \tNOUN\n",
            "an             \tDET\n",
            "investigation  \tNOUN\n",
            "of             \tADP\n",
            "Atlanta's      \tNOUN\n",
            "recent         \tADJ\n",
            "primary        \tNOUN\n",
            "election       \tNOUN\n",
            "produced       \tVERB\n",
            "``             \t.\n",
            "no             \tDET\n",
            "evidence       \tNOUN\n",
            "''             \t.\n",
            "that           \tADP\n",
            "any            \tDET\n",
            "irregularities \tNOUN\n",
            "took           \tVERB\n",
            "place          \tNOUN\n",
            ".              \t.\n"
          ]
        }
      ],
      "source": [
        "for word, tag in data[0]:\n",
        "    print('{:15}\\t{}'.format(word, tag))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epdW8u_YXcAv"
      },
      "source": [
        "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
        "\n",
        "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTai8Ta0lgwL",
        "outputId": "da62a113-9b4b-42da-d07b-13c6c280a31f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words count in train set: 739769\n",
            "Words count in val set: 130954\n",
            "Words count in test set: 290469\n"
          ]
        }
      ],
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
        "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
        "print('Words count in test set:', sum(len(sent) for sent in test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eChdLNGtXyP0"
      },
      "source": [
        "Построим маппинги из слов в индекс и из тега в индекс:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCjwwDs6Zq9x",
        "outputId": "ef53325f-5745-4913-db3d-f769c08de16e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words in train = 45441. Tags = {'PRON', 'ADP', 'CONJ', 'PRT', 'VERB', 'ADV', '.', 'NOUN', 'DET', 'NUM', 'X', 'ADJ'}\n"
          ]
        }
      ],
      "source": [
        "words = {word for sample in train_data for word, tag in sample}\n",
        "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
        "word2ind['<pad>'] = 0\n",
        "\n",
        "tags = {tag for sample in train_data for word, tag in sample}\n",
        "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
        "tag2ind['<pad>'] = 0\n",
        "\n",
        "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "URC1B2nvPGFt",
        "outputId": "a61e557b-21c5-40b5-b0d2-d5894941c316"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
        "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "bar_width = 0.35\n",
        "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
        "plt.xticks(np.arange(len(tags)), tags)\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gArQwbzWWkgi"
      },
      "source": [
        "## Бейзлайн\n",
        "\n",
        "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
        "\n",
        "Простейший вариант - униграммная модель, учитывающая только слово:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rWmSToIaeAo",
        "outputId": "18ceba1e-2f48-435e-c7ce-24e22e9558ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of unigram tagger = 92.62%\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "\n",
        "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
        "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t3xyYd__8d-"
      },
      "source": [
        "## Увеличиваем контекст с рекуррентными сетями\n",
        "\n",
        "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
        "\n",
        "Омонимия - основная причина, почему униграмная модель плоха:  \n",
        "*“he cashed a check at the **bank**”*  \n",
        "vs  \n",
        "*“he sat on the **bank** of the river”*\n",
        "\n",
        "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
        "\n",
        "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
        "\n",
        "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
        "\n",
        "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtRbz1SwgEqc"
      },
      "outputs": [],
      "source": [
        "def convert_data(data, word2ind, tag2ind):\n",
        "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
        "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhsTKZalfih6"
      },
      "outputs": [],
      "source": [
        "def iterate_batches(data, batch_size):\n",
        "    X, y = data\n",
        "    n_samples = len(X)\n",
        "\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        \n",
        "        batch_indices = indices[start:end]\n",
        "        \n",
        "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
        "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        \n",
        "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
        "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
        "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
        "            \n",
        "        yield X_batch, y_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4XsRII5kW5x",
        "outputId": "e0e8f67c-36e2-4ae4-ced9-0791fc24ed59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 4), (32, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
        "\n",
        "X_batch.shape, y_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVEHju54d68T"
      },
      "outputs": [],
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._emb = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self._lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count)\n",
        "        self._out_layer = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        emb = self._emb(inputs)\n",
        "        out, _ = self._lstm(emb)\n",
        "        return self._out_layer(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_HA8zyheYGH"
      },
      "source": [
        "Посчитаем accuracy и loss, а заодно проверим, что модель работает"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbrxsZ2mehWB",
        "outputId": "a5e9b1cf-508e-4a98-cbb2-a8c9dbbfffa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09782608695652174"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ")\n",
        "\n",
        "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
        "\n",
        "logits = model(X_batch)\n",
        "\n",
        "preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "mask = (y_batch != 0).float()\n",
        "correct_count = ((preds == y_batch).float() * mask).sum().item()\n",
        "total_count = mask.sum().item()\n",
        "\n",
        "correct_count / total_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMUyUm1hgpe3",
        "outputId": "771a60b7-063a-4551-b92a-7ce8850ddbb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.6114, grad_fn=<NllLoss2DBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion(logits.transpose(2, 1), y_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FprPQ0gllo7b"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    correct_count = 0\n",
        "    sum_count = 0\n",
        "    \n",
        "    is_train = optimizer is not None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
        "                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "                logits = model(X_batch)\n",
        "\n",
        "                loss = criterion(logits.view(-1, logits.shape[-1]), y_batch.view(-1))\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "                mask = (y_batch != 0).float()\n",
        "                cur_correct_count = ((preds == y_batch).float() * mask).sum().item()\n",
        "                cur_sum_count = mask.sum().item()\n",
        "\n",
        "                correct_count += cur_correct_count\n",
        "                sum_count += cur_sum_count\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
        "                )\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
        "            )\n",
        "\n",
        "    return epoch_loss / batches_count, correct_count / sum_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
        "        val_data=None, val_batch_size=None):\n",
        "        \n",
        "    if val_data is not None and val_batch_size is not None:\n",
        "        val_batch_size = batch_size\n",
        "        \n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if val_data is not None:\n",
        "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "Pqfbeh1ltEYa",
        "outputId": "706de9e1-5daa-4931-a30a-ce333b8a745f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1 / 50] Train: Loss = 0.31813, Accuracy = 71.94%: 100%|██████████| 572/572 [00:06<00:00, 90.82it/s] \n",
            "[1 / 50]   Val: Loss = 0.16301, Accuracy = 84.66%: 100%|██████████| 101/101 [00:00<00:00, 179.62it/s]\n",
            "[2 / 50] Train: Loss = 0.10119, Accuracy = 89.90%: 100%|██████████| 572/572 [00:05<00:00, 111.23it/s]\n",
            "[2 / 50]   Val: Loss = 0.12036, Accuracy = 89.44%: 100%|██████████| 101/101 [00:00<00:00, 174.65it/s]\n",
            "[3 / 50] Train: Loss = 0.06781, Accuracy = 93.24%: 100%|██████████| 572/572 [00:05<00:00, 111.41it/s]\n",
            "[3 / 50]   Val: Loss = 0.10845, Accuracy = 91.10%: 100%|██████████| 101/101 [00:00<00:00, 189.39it/s]\n",
            "[4 / 50] Train: Loss = 0.05063, Accuracy = 94.84%: 100%|██████████| 572/572 [00:05<00:00, 111.33it/s]\n",
            "[4 / 50]   Val: Loss = 0.10419, Accuracy = 92.07%: 100%|██████████| 101/101 [00:00<00:00, 192.08it/s]\n",
            "[5 / 50] Train: Loss = 0.04053, Accuracy = 95.83%: 100%|██████████| 572/572 [00:05<00:00, 110.55it/s]\n",
            "[5 / 50]   Val: Loss = 0.09989, Accuracy = 92.64%: 100%|██████████| 101/101 [00:00<00:00, 185.40it/s]\n",
            "[6 / 50] Train: Loss = 0.03283, Accuracy = 96.59%: 100%|██████████| 572/572 [00:05<00:00, 95.84it/s] \n",
            "[6 / 50]   Val: Loss = 0.09815, Accuracy = 92.97%: 100%|██████████| 101/101 [00:00<00:00, 176.63it/s]\n",
            "[7 / 50] Train: Loss = 0.02735, Accuracy = 97.17%: 100%|██████████| 572/572 [00:05<00:00, 110.17it/s]\n",
            "[7 / 50]   Val: Loss = 0.10292, Accuracy = 93.12%: 100%|██████████| 101/101 [00:00<00:00, 176.49it/s]\n",
            "[8 / 50] Train: Loss = 0.02260, Accuracy = 97.65%: 100%|██████████| 572/572 [00:05<00:00, 110.87it/s]\n",
            "[8 / 50]   Val: Loss = 0.10611, Accuracy = 93.21%: 100%|██████████| 101/101 [00:00<00:00, 176.09it/s]\n",
            "[9 / 50] Train: Loss = 0.01886, Accuracy = 98.04%: 100%|██████████| 572/572 [00:05<00:00, 109.27it/s]\n",
            "[9 / 50]   Val: Loss = 0.10703, Accuracy = 93.31%: 100%|██████████| 101/101 [00:00<00:00, 190.16it/s]\n",
            "[10 / 50] Train: Loss = 0.01569, Accuracy = 98.37%: 100%|██████████| 572/572 [00:05<00:00, 110.91it/s]\n",
            "[10 / 50]   Val: Loss = 0.10937, Accuracy = 93.26%: 100%|██████████| 101/101 [00:00<00:00, 193.78it/s]\n",
            "[11 / 50] Train: Loss = 0.01303, Accuracy = 98.66%: 100%|██████████| 572/572 [00:05<00:00, 109.52it/s]\n",
            "[11 / 50]   Val: Loss = 0.11547, Accuracy = 93.28%: 100%|██████████| 101/101 [00:00<00:00, 182.05it/s]\n",
            "[12 / 50] Train: Loss = 0.01082, Accuracy = 98.91%: 100%|██████████| 572/572 [00:05<00:00, 110.84it/s]\n",
            "[12 / 50]   Val: Loss = 0.11994, Accuracy = 93.23%: 100%|██████████| 101/101 [00:00<00:00, 184.22it/s]\n",
            "[13 / 50] Train: Loss = 0.00831, Accuracy = 98.90%:   4%|▍         | 22/572 [00:00<00:04, 111.16it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a33578919a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n\u001b[0;32m---> 10\u001b[0;31m     batch_size=64, val_data=(X_val, y_val), val_batch_size=512)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-30eedee31b9c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, criterion, optimizer, train_data, epochs_count, batch_size, val_data, val_batch_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mname_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[{} / {}] '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Train:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-30eedee31b9c>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(model, criterion, data, batch_size, optimizer, name)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-d4b17ce0da16>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_out_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 770\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98wr38_rw55D",
        "outputId": "4ed5543a-922a-4eb2-c883-bdc5f62cfc71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy = 93.37%\n"
          ]
        }
      ],
      "source": [
        "correct_count = 0\n",
        "sum_count = 0\n",
        "\n",
        "for X_batch, y_batch in iterate_batches((X_test, y_test), 64):\n",
        "    X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "    logits = model(X_batch)\n",
        "\n",
        "    preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    mask = (y_batch != 0).float()\n",
        "    cur_correct_count = ((preds == y_batch).float() * mask).sum().item()\n",
        "    cur_sum_count = mask.sum().item()\n",
        "                \n",
        "    correct_count += cur_correct_count\n",
        "    sum_count += cur_sum_count\n",
        "\n",
        "print(f'Test accuracy = {round(correct_count / sum_count * 100, 2)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXUTSFaEHbDG"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
        "\n",
        "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
        "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGIxc7dDt1A1"
      },
      "outputs": [],
      "source": [
        "class BidirectionalLSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._emb = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self._lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n",
        "        self._out_layer = nn.Linear(lstm_hidden_dim * 2, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        emb = self._emb(inputs)\n",
        "        out, _ = self._lstm(emb)\n",
        "        return self._out_layer(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "wyFL_YH342h-",
        "outputId": "6c377df3-d45d-4b02-aa75-7a073a92ab3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1 / 50] Train: Loss = 0.26250, Accuracy = 75.71%: 100%|██████████| 572/572 [00:06<00:00, 93.89it/s]\n",
            "[1 / 50]   Val: Loss = 0.11477, Accuracy = 88.97%: 100%|██████████| 101/101 [00:00<00:00, 156.42it/s]\n",
            "[2 / 50] Train: Loss = 0.07678, Accuracy = 92.50%: 100%|██████████| 572/572 [00:05<00:00, 99.60it/s]\n",
            "[2 / 50]   Val: Loss = 0.07743, Accuracy = 93.07%: 100%|██████████| 101/101 [00:00<00:00, 172.65it/s]\n",
            "[3 / 50] Train: Loss = 0.04927, Accuracy = 95.27%: 100%|██████████| 572/572 [00:05<00:00, 95.99it/s]\n",
            "[3 / 50]   Val: Loss = 0.06533, Accuracy = 94.46%: 100%|██████████| 101/101 [00:00<00:00, 171.00it/s]\n",
            "[4 / 50] Train: Loss = 0.03505, Accuracy = 96.68%: 100%|██████████| 572/572 [00:06<00:00, 94.34it/s]\n",
            "[4 / 50]   Val: Loss = 0.06001, Accuracy = 94.96%: 100%|██████████| 101/101 [00:00<00:00, 174.32it/s]\n",
            "[5 / 50] Train: Loss = 0.02598, Accuracy = 97.59%: 100%|██████████| 572/572 [00:05<00:00, 95.40it/s]\n",
            "[5 / 50]   Val: Loss = 0.05813, Accuracy = 95.39%: 100%|██████████| 101/101 [00:00<00:00, 165.19it/s]\n",
            "[6 / 50] Train: Loss = 0.01913, Accuracy = 98.25%: 100%|██████████| 572/572 [00:05<00:00, 95.53it/s]\n",
            "[6 / 50]   Val: Loss = 0.05569, Accuracy = 95.71%: 100%|██████████| 101/101 [00:00<00:00, 169.07it/s]\n",
            "[7 / 50] Train: Loss = 0.01385, Accuracy = 98.75%: 100%|██████████| 572/572 [00:05<00:00, 95.54it/s]\n",
            "[7 / 50]   Val: Loss = 0.05577, Accuracy = 95.84%: 100%|██████████| 101/101 [00:00<00:00, 180.51it/s]\n",
            "[8 / 50] Train: Loss = 0.00983, Accuracy = 99.14%: 100%|██████████| 572/572 [00:06<00:00, 89.89it/s] \n",
            "[8 / 50]   Val: Loss = 0.05752, Accuracy = 95.94%: 100%|██████████| 101/101 [00:00<00:00, 180.79it/s]\n",
            "[9 / 50] Train: Loss = 0.00729, Accuracy = 99.24%:  60%|█████▉    | 341/572 [00:03<00:02, 93.38it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-37f3c3e1a035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n\u001b[0;32m---> 10\u001b[0;31m     batch_size=64, val_data=(X_val, y_val), val_batch_size=512)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-30eedee31b9c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, criterion, optimizer, train_data, epochs_count, batch_size, val_data, val_batch_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mname_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[{} / {}] '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Train:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-30eedee31b9c>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(model, criterion, data, batch_size, optimizer, name)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n\u001b[0;32m---> 42\u001b[0;31m                     name, loss.item(), cur_correct_count / cur_sum_count)\n\u001b[0m\u001b[1;32m     43\u001b[0m                 )\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mset_description\u001b[0;34m(self, desc, refresh)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_description_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mprint_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisp_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mfp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mfp_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mlast_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = BidirectionalLSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5mutipY8QGZ",
        "outputId": "448c137e-3b2f-4a65-f54e-04eb8ae25ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy = 95.87%\n"
          ]
        }
      ],
      "source": [
        "correct_count = 0\n",
        "sum_count = 0\n",
        "\n",
        "for X_batch, y_batch in iterate_batches((X_test, y_test), 64):\n",
        "    X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "    logits = model(X_batch)\n",
        "\n",
        "    preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    mask = (y_batch != 0).float()\n",
        "    cur_correct_count = ((preds == y_batch).float() * mask).sum().item()\n",
        "    cur_sum_count = mask.sum().item()\n",
        "                \n",
        "    correct_count += cur_correct_count\n",
        "    sum_count += cur_sum_count\n",
        "\n",
        "print(f'Test accuracy = {round(correct_count / sum_count * 100, 2)}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTXmYGD_ANhm"
      },
      "source": [
        "### Предобученные эмбеддинги\n",
        "\n",
        "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
        "\n",
        "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZpY_Q1xZ18h",
        "outputId": "e860eb01-c37f-4161-88ae-06d555a09705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load('glove-wiki-gigaword-100')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYogOoKlgtcf"
      },
      "source": [
        "Построим подматрицу для слов из нашей тренировочной выборки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsCstxiO03oT",
        "outputId": "8716df79-24a5-4d63-8ac9-c796c49ec4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Know 38736 out of 45441 word embeddings\n"
          ]
        }
      ],
      "source": [
        "known_count = 0\n",
        "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
        "for word, ind in word2ind.items():\n",
        "    word = word.lower()\n",
        "    if word in w2v_model.vocab:\n",
        "        embeddings[ind] = w2v_model.get_vector(word)\n",
        "        known_count += 1\n",
        "        \n",
        "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcG7i-R8hbY3"
      },
      "source": [
        "Сделаем модель с предобученной матрицей. Будем использовать `nn.Embedding.from_pretrained`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxaRBpQd0pat"
      },
      "outputs": [],
      "source": [
        "class BidirectionalLSTMTaggerWithPretrainedEmbs(nn.Module):\n",
        "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._emb = nn.Embedding.from_pretrained(embeddings)\n",
        "        self._lstm = nn.LSTM(embeddings.shape[1], lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n",
        "        self._out_layer = nn.Linear(lstm_hidden_dim * 2, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        emb = self._emb(inputs)\n",
        "        out, _ = self._lstm(emb)\n",
        "        return self._out_layer(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "EBtI6BDE-Fc7",
        "outputId": "da305453-3e9f-435e-8f03-fc2e5aa391a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1 / 50] Train: Loss = 0.57125, Accuracy = 83.25%: 100%|██████████| 572/572 [00:04<00:00, 122.05it/s]\n",
            "[1 / 50]   Val: Loss = 0.26378, Accuracy = 92.35%: 100%|██████████| 101/101 [00:00<00:00, 193.31it/s]\n",
            "[2 / 50] Train: Loss = 0.19244, Accuracy = 94.33%: 100%|██████████| 572/572 [00:04<00:00, 122.86it/s]\n",
            "[2 / 50]   Val: Loss = 0.17718, Accuracy = 94.64%: 100%|██████████| 101/101 [00:00<00:00, 193.06it/s]\n",
            "[3 / 50] Train: Loss = 0.13671, Accuracy = 95.91%: 100%|██████████| 572/572 [00:04<00:00, 125.75it/s]\n",
            "[3 / 50]   Val: Loss = 0.14210, Accuracy = 95.64%: 100%|██████████| 101/101 [00:00<00:00, 172.89it/s]\n",
            "[4 / 50] Train: Loss = 0.11025, Accuracy = 96.68%: 100%|██████████| 572/572 [00:04<00:00, 124.67it/s]\n",
            "[4 / 50]   Val: Loss = 0.12672, Accuracy = 96.03%: 100%|██████████| 101/101 [00:00<00:00, 172.87it/s]\n",
            "[5 / 50] Train: Loss = 0.09444, Accuracy = 97.11%: 100%|██████████| 572/572 [00:04<00:00, 125.46it/s]\n",
            "[5 / 50]   Val: Loss = 0.11624, Accuracy = 96.36%: 100%|██████████| 101/101 [00:00<00:00, 169.35it/s]\n",
            "[6 / 50] Train: Loss = 0.08399, Accuracy = 97.41%: 100%|██████████| 572/572 [00:04<00:00, 129.85it/s]\n",
            "[6 / 50]   Val: Loss = 0.10782, Accuracy = 96.61%: 100%|██████████| 101/101 [00:00<00:00, 175.48it/s]\n",
            "[7 / 50] Train: Loss = 0.07641, Accuracy = 97.64%: 100%|██████████| 572/572 [00:04<00:00, 129.15it/s]\n",
            "[7 / 50]   Val: Loss = 0.10262, Accuracy = 96.71%: 100%|██████████| 101/101 [00:00<00:00, 197.09it/s]\n",
            "[8 / 50] Train: Loss = 0.07004, Accuracy = 97.83%: 100%|██████████| 572/572 [00:04<00:00, 126.51it/s]\n",
            "[8 / 50]   Val: Loss = 0.10028, Accuracy = 96.81%: 100%|██████████| 101/101 [00:00<00:00, 181.49it/s]\n",
            "[9 / 50] Train: Loss = 0.06532, Accuracy = 97.98%: 100%|██████████| 572/572 [00:04<00:00, 129.04it/s]\n",
            "[9 / 50]   Val: Loss = 0.09704, Accuracy = 96.89%: 100%|██████████| 101/101 [00:00<00:00, 198.60it/s]\n",
            "[10 / 50] Train: Loss = 0.05781, Accuracy = 98.05%:  89%|████████▉ | 509/572 [00:04<00:00, 126.69it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-50e77739248c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n\u001b[0;32m---> 10\u001b[0;31m     batch_size=64, val_data=(X_val, y_val), val_batch_size=512)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-30eedee31b9c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, criterion, optimizer, train_data, epochs_count, batch_size, val_data, val_batch_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mname_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'[{} / {}] '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Train:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-30eedee31b9c>\u001b[0m in \u001b[0;36mdo_epoch\u001b[0;34m(model, criterion, data, batch_size, optimizer, name)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = BidirectionalLSTMTaggerWithPretrainedEmbs(\n",
        "    embeddings=torch.FloatTensor(embeddings),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPUuAPGhEGVR",
        "outputId": "4f1dc171-d964-441d-eda6-ba96975f8702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy = 96.99%\n"
          ]
        }
      ],
      "source": [
        "correct_count = 0\n",
        "sum_count = 0\n",
        "\n",
        "for X_batch, y_batch in iterate_batches((X_test, y_test), 64):\n",
        "    X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "    logits = model(X_batch)\n",
        "\n",
        "    preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    mask = (y_batch != 0).float()\n",
        "    cur_correct_count = ((preds == y_batch).float() * mask).sum().item()\n",
        "    cur_sum_count = mask.sum().item()\n",
        "                \n",
        "    correct_count += cur_correct_count\n",
        "    sum_count += cur_sum_count\n",
        "\n",
        "print(f'Test accuracy = {round(correct_count / sum_count * 100, 2)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoxlK4Zf8Ybq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}